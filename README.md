![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![Framework](https://img.shields.io/badge/Framework-LangGraph-green)
![Architecture](https://img.shields.io/badge/Architecture-Agentic%20System-orange)
![Output](https://img.shields.io/badge/Output-Structured%20JSON-blueviolet)

# Kasparro â€“ Multi-Agent Content Generation System

This repository contains a **production-style, agentic content generation system** built as part of the **Kasparro Applied AI Engineer assignment**.

The system demonstrates how a small, structured product dataset can be transformed into multiple **machine-readable content pages** using **LLM-backed agents**, **explicit orchestration**, **schema validation**, and **robust automation design**.

---

## ğŸš€ What This Project Does

Given a structured product dataset, the system autonomously generates:

- **FAQ Page** (`faq.json`) â€” 15+ user questions and answers
- **Product Page** (`product_page.json`) â€” structured product description
- **Comparison Page** (`comparison_page.json`) â€” GlowBoost vs a fictional product

All outputs are:
- **LLM-generated** (no hardcoded content)
- **Schema-validated** (machine-readable JSON)
- **Orchestrated via LangGraph**
- **Produced by specialized agents**, not a monolithic script

---

## ğŸ§  System Architecture

The system is implemented as a **LangGraph-based multi-agent pipeline**, where each agent performs a single responsibility and communicates through a shared graph state.

```mermaid
graph TD
    Input[Product Dataset] --> QGen[Question Generation Agent]
    QGen --> FAQ[FAQ Agent]
    FAQ --> Product[Product Page Agent]
    Product --> Compare[Comparison Agent]
    Compare --> Validate[Validation Agent]
    Validate --> Output[Output Writer Agent]
````

Key architectural characteristics:

* Explicit DAG execution
* Clear agent boundaries
* No global state
* Retry handling for LLM failures
* Validation gates before persistence

---

## ğŸ“ Repository Structure

```text
.
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ question_agent.py
â”‚   â”œâ”€â”€ faq_agent.py
â”‚   â”œâ”€â”€ product_agent.py
â”‚   â”œâ”€â”€ comparison_agent.py
â”‚   â”œâ”€â”€ validation_agent.py
â”‚   â”œâ”€â”€ output_agent.py
â”‚   â”œâ”€â”€ retry_utils.py
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ graph/
â”‚   â”œâ”€â”€ graph.py
â”‚   â”œâ”€â”€ state.py
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ schemas/
â”‚   â”œâ”€â”€ faq.py
â”‚   â”œâ”€â”€ product.py
â”‚   â”œâ”€â”€ comparison.py
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ product_input.json
â”‚   â””â”€â”€ fictional_product_b.json
â”‚
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ faq.json
â”‚   â”œâ”€â”€ product_page.json
â”‚   â””â”€â”€ comparison_page.json
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_faq_count.py
â”‚   â””â”€â”€ test_pipeline_outputs.py
â”‚
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ projectdocumentation.md
â”‚
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .env.example
```

---

## â–¶ï¸ How to Run

### Prerequisites

* Python 3.10+
* OpenAI API key

### Setup

```bash
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

Create a `.env` file using the provided template:

```env
OPENAI_API_KEY=your_api_key_here
```

### Run the Pipeline

```bash
python main.py
```

### Run Tests

```bash
pytest
```

---

## ğŸ§© Design Principles

* **Agentic orchestration**: Each task is handled by a dedicated agent.
* **LLM-based reasoning**: No deterministic or hardcoded content generation.
* **Schema-driven templates**: Pydantic schemas act as structural templates.
* **Explicit validation**: Outputs are validated before persistence.
* **Robust execution**: Retry logic and failure isolation.
* **Production-oriented design**: Extensible, testable, and auditable.

---

## ğŸ“„ Documentation

Detailed system design, architecture rationale, and engineering decisions are documented in:

```
docs/projectdocumentation.md
```

---

## âš ï¸ Constraints & Notes

* No external data or research is used.
* Comparison products are fictional and defined in input data.
* The project focuses on **automation and system design**, not UI rendering.

---

## âœ… Conclusion

This project demonstrates a **real-world applied AI engineering approach** to building agentic automation systems. By combining **LangGraph orchestration**, **LLM-backed agents**, and **schema-enforced outputs**, the system avoids brittle prompt-only solutions and delivers a robust, extensible content generation pipeline.

